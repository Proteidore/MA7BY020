{
  "hash": "49e02c6aa326011140c8ab9e36d5aa4e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tables manipulation with dplyr\"\ncategories: [dplyr, SQL, tables]\ndate: \"2021/12/21 (updated: 2025-01-29)\"\n\n\nbibliography: mon_chapeau.bib\n\nformat: \n  revealjs:\n    header: \"Table calculus with dplyr\"\n\nengine: knitr\n# standalone: true\n---\n\n\n\n\n\n\n\n\n\n# Tables  {background-color=\"#1c191c\"}\n\n\n\n\n## Tables (examples)\n\n- Speadsheets (Excel)\n\n- {{< fa database >}} Relational tables\n\n- Dataframes in datascience frameworks\n\n  - {{< fa brands r-project >}}: `data.frame`, `tibble`, ...\n  - {{< fa brands python >}}: `pandas.dataframe`\n  - `spark`: `dataframe`\n  - `Dask`: `dataframe`\n  - and many others\n\n\n\n\n## Tables (Why ?)\n\nIn Data Science, each framework comes with its own flavor(s) of table(s)\n\n{{< fa database >}} Tables from relational databases serve as inspiration\n\nIn {{< fa brands r-project >}} legacy dataframes shape the life of statisticians and data scientists\n\nThe purpose of this session is\n\n- describe dataframes from an end-user viewpoint (we leave aside implementations)\n\n- presenting tools for\n  - accessing information within dataframes (*querying*)\n  - summarizing information (*aggregation queries*)\n  - cleaning/cleaning dataframes  (*tidying*)\n\n\n\n\n\n## Loading tables and packages\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(\"tidyverse\")      # All we need is there\nrequire(\"nycflights13\")    # for flight data\nrequire(\"gt\")\nrequire(\"kableExtra\")\n# \ndata(flights)\n```\n:::\n\n\n\n\n\n## About loaded packages \n\n- Metapackage [`tidyverse`](https://www.tidyverse.org) provides tools to create, query, tidy dataframes as well as tools to load data from various sources and save them in persistent storage\n\n- [`nycflights13`](https://github.com/tidyverse/nycflights13) provides the dataframes we play with\n\n- [`gt`](https://gt.rstudio.com)  for tayloring table displays\n\n\n\n## The `flights` table\n\n\n::: {.columns}\n\n::: {.column}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(flights) |>\n  glimpse(width = 30) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 6\nColumns: 19\n$ year           <int> 2013,…\n$ month          <int> 1, 1,…\n$ day            <int> 1, 1,…\n$ dep_time       <int> 517, …\n$ sched_dep_time <int> 515, …\n$ dep_delay      <dbl> 2, 4,…\n$ arr_time       <int> 830, …\n$ sched_arr_time <int> 819, …\n$ arr_delay      <dbl> 11, 2…\n$ carrier        <chr> \"UA\",…\n$ flight         <int> 1545,…\n$ tailnum        <chr> \"N142…\n$ origin         <chr> \"EWR\"…\n$ dest           <chr> \"IAH\"…\n$ air_time       <dbl> 227, …\n$ distance       <dbl> 1400,…\n$ hour           <dbl> 5, 5,…\n$ minute         <dbl> 15, 2…\n$ time_hour      <dttm> 2013…\n```\n\n\n:::\n:::\n\n\n\n:::\n::: {.column}\n\n- A dataframe is a two-ways (two-dimensional) table\n\n- `head(df)` displays the first 6 rows of its first argument\n\n- The vectors making a dataframe may have different types/classes (a dataframe is not a matrix)\n\n- Compare `str()`, `glimpse()`, `head()`\n\n:::\n::: \n\n\n\n## Table schema\n\n\n\nA table is a _list_ of _columns_\n\nEach _column_ has\n\n- _name_ and\n- _type_ (_class_ in {{< fa brands r-project >}}\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nglimpse(flights,   #<<\n        width=50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 336,776\nColumns: 19\n$ year           <int> 2013, 2013, 2013, 2013, 2…\n$ month          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       <int> 517, 533, 542, 544, 554, …\n$ sched_dep_time <int> 515, 529, 540, 545, 600, …\n$ dep_delay      <dbl> 2, 4, 2, -1, -6, -4, -5, …\n$ arr_time       <int> 830, 850, 923, 1004, 812,…\n$ sched_arr_time <int> 819, 830, 850, 1022, 837,…\n$ arr_delay      <dbl> 11, 20, 33, -18, -25, 12,…\n$ carrier        <chr> \"UA\", \"UA\", \"AA\", \"B6\", \"…\n$ flight         <int> 1545, 1714, 1141, 725, 46…\n$ tailnum        <chr> \"N14228\", \"N24211\", \"N619…\n$ origin         <chr> \"EWR\", \"LGA\", \"JFK\", \"JFK…\n$ dest           <chr> \"IAH\", \"IAH\", \"MIA\", \"BQN…\n$ air_time       <dbl> 227, 227, 160, 183, 116, …\n$ distance       <dbl> 1400, 1416, 1089, 1576, 7…\n$ hour           <dbl> 5, 5, 5, 5, 6, 5, 6, 6, 6…\n$ minute         <dbl> 15, 29, 40, 45, 0, 58, 0,…\n$ time_hour      <dttm> 2013-01-01 05:00:00, 201…\n```\n\n\n:::\n:::\n\n\n\n\n\n\n##\n\n- `flights` has 19 columns\n- Each column is  a sequence (`vector`) of items with the same type/class\n- All columns have the same length\n- `flights` has 336776 rows\n- In {{< fa database >}} parlance, a row is (often) called a _tuple_\n- In {{< fa database >}} parlance, a column is (often) called a _variable_\n\n\n\n## Column types\n\n::: {.columns}\n::: {.column}\n\n| class |  columns |\n|:--:|:-----|\n| `integer`   |  'year' 'month' 'day' 'dep_time' 'sched_dep_time' 'arr_time' 'sched_arr_time' 'flight'  |\n| `numeric`  | 'dep_delay' 'arr_delay' 'air_time' 'distance' 'hour' 'minute'  |\n| `character`   |  'carrier' 'tailnum' 'origin' 'dest' |\n| `POSIXct`   |  'time_hour' |\n| `POSIXt`   |  'time_hour' |\n\n\n:::\n::: {.column}\n\n\nA column, as a vector, may be belong to different classes\n\nOther classes:  `factor` for categorical variables\n\nColumns `dest`, `origin` `carrier` could be coerced as factors\n\nShould columns `dest`  and `origin` be coerced to the same factor?\n\n:::\n::: \n\n\n\n\n\n\n\n## `nycflights13`\n\n\n::: {.center}\n\n\n![](/images/schema-nycflights.png){width=\"40%\"}\n\n\n:::\n\n\n\n## Columns specification\n\n\n::: {.columns}\n\n::: {.column width=\"30%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas.col_spec(flights)\n```\n:::\n\n\n:::\n\n::: {.column}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncols(\n  year = col_integer(),\n  month = col_integer(),\n  day = col_integer(),\n  dep_time = col_integer(),\n  sched_dep_time = col_integer(),\n  dep_delay = col_double(),\n  arr_time = col_integer(),\n  sched_arr_time = col_integer(),\n  arr_delay = col_double(),\n  carrier = col_character(),\n  flight = col_integer(),\n  tailnum = col_character(),\n  origin = col_character(),\n  dest = col_character(),\n  air_time = col_double(),\n  distance = col_double(),\n  hour = col_double(),\n  minute = col_double(),\n  time_hour = col_datetime(format = \"\")\n)\n```\n:::\n\n\n:::\n::: \n\n\n\n##\n\n$\\approx$ table schema in relational databases\n\nColumn specifications are useful when loading dataframes from structured text files\nlike `.csv` files\n\n`.csv` files do not contain typing information\n\nFile loaders from package `readr` can be tipped about column classes using column specifications\n\n\n\n# SQL and Relational algebra with `dplyr` {background-color=\"#1c191c\"}\n\n\n\n## {{< fa syringe >}}\n\n- SQL stands for structured/simple Query Language\n\n- A query language elaborated during the 1970's at IBM by E. Codd\n\n- Geared towards exploitation of collections of relational tables\n\n- Less powerful but simpler to use than a programming language\n\n- `dplyr` is a principled {{< fa brands r-project >}}-friendly\nimplementation of SQL ideas (and other things)\n\nAt the core of SQL lies the idea of a table calculus called **relational algebra**\n\n\n\n## Relational algebra (basics)\n\nConvention: $R$  is a table with columns $A_1, \\ldots, A_k$\n\n::: {.callout-note}\n\n### Projection (picking columns)\n\n$\\pi(R, A_1, A_3)$\n\n:::\n\n\n::: {.callout-note}\n\n### Selection/Filtering (picking rows)\n\n$\\sigma(R, {\\text{condition}})$\n\n:::\n\n::: {.callout-note}\n\n###  Join (mulitple tables operation)\n\n$\\bowtie(R,S, {\\text{condition}})$\n\n:::\n\n{{< fa hand-point-right >}} Any operation produces a table\n\n{{< fa hand-point-right >}} The schema of the derived table depends on the operation (but does not depend on the content/value of the operands)\n\n\n##\n\nTable calculus relies on a small set of basic operations $\\pi, \\sigma, \\bowtie$\n\nEach operation has one or two table **operands** and produce a table\n\n{{< fa exclamation-triangle >}} There is more to SQL than relational algebra\n\n\n## Projection  $\\pi$\n\n\n$\\pi(R, {A_1, A_3})$\n\nA projection  $\\pi(\\cdot, {A_1, A_3})$ is defined by a set of column names, say $A_1, A_3$\n\nIf $R$ has columns with given names, the result is a table with names $A_1, A_3$ and one row per row of $R$\n\nA projection is parametrized by a list of column names\n\n\n\n\n## {{< fa tools >}} Package `dplyr`\n\n::: {.columns}\n::: {.column width=\"30%\"}\n\n- [_Tranformation_ chapter in R4DS](https://r4ds.had.co.nz/transform.html)\n\n- [Cheat sheet I](https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf)\n\n- [Cheat sheet II](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)\n\n:::\n::: {.column width=\"70%\"}\n\n\n\n::: {.cell}\n<iframe src=\"https://dplyr.tidyverse.org\" width=\"960\" height=\"400px\" data-external=\"1\"></iframe>\n:::\n\n\n\n[https://dplyr.tidyverse.org](https://dplyr.tidyverse.org)\n\n::: \n\n:::\n\n##\n\nBase {{< fa brands r-project >}} provides tools to perform relational algebra operations\n\nBut:\n\n- Base {{< fa brands r-project >}} does not provide a consistent API\n\n- The lack of a consistent API makes operation chaining tricky\n\n\n\n## `dplyr` verbs\n\nFive basic verbs:\n\n- Pick observations/rows by their values (`filter()`)   σ(...) \n\n- Pick variables by their names (`select()`)     π(...)\n\n- Reorder the rows (`arrange()`)\n\n- Create new variables with functions of existing variables (`mutate()`)\n\n- Collapse many values down to a single summary (`summarise()`)\n\n. . .\n\nAnd\n\n- `group_by()`  changes the scope of each function from operating on the entire dataset to operating on it group-by-group\n\n\n\n\n\n## {{< fa umbrella-beach >}} tidyverse\n\n::: {.columns}\n\n::: {.column}\n> All verbs work similarly:\n\n> The first argument is a data frame (table).\n\n> The subsequent arguments describe what to do with the data frame, using the variable/column names (without quotes)\n\n> The result is a new data frame (table)\n\n:::\n\n::: {.column}\n\n\n\n::: {.cell}\n<iframe src=\"https://dplyr.tidyverse.org\" width=\"960\" height=\"400px\" data-external=\"1\"></iframe>\n:::\n\n\n\n:::\n:::\n\n\n\n\n## `dplyr::select()` as a projection operator (π)\n\n$\\pi(R, \\underbrace{A_1, \\ldots, A_3}_{\\text{column names}})$\n\n```{.r}\nselect(R, A1, A3) #<<\n```\n\nor,  equivalently\n\n```{.r}\nR |> select(A1, A3) #<<\n```\n\n{{< fa hand-point-right >}} `|>` is the pipe operator \n\n{{< fa hat-wizard >}} `x |> f(y, z)` is translated to `f(x, y, z)` and then evaluated\n\n##  `dplyr::select()` \n\n- Function `select` has a variable number of arguments\n\n- Function `select`  has a variable number of arguments\n\n- Function `select` allows to pick column by names (and much more)\n\n- Note that in the current environment, there are no objects called `A1`, `A3`\n\n- The consistent API allows to use the pipe operator\n\n::: {.callout-caution}\n\nThere is also a `select()` function  in base `R`\n\n:::\n\n## Toy tables\n\n::: {.columns}\n::: {.column}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam <- set.seed(42)\n\nR <-  tibble(A1=seq(2, 10, 2),\n             A2=sample(letters, 5),\n             A3=seq(from=date(\"2021-10-21\"),\n                    to=date(\"2021-11-20\"),\n                    by=7),\n             D=sample(letters, 5))\n\nS <- tibble(E=c(3,4,6,9, 10),\n            F=sample(letters, 5),\n            G=seq(from=date(\"2021-10-21\"),\n                   to=date(\"2021-10-21\")+4, by=1),\n            D=sample(letters,5)\n          )\n```\n:::\n\n\n\n:::\n::: {.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: R\n\n| A1|A2 |A3         |D  |\n|--:|:--|:----------|:--|\n|  2|q  |2021-10-21 |r  |\n|  4|e  |2021-10-28 |q  |\n|  6|a  |2021-11-04 |o  |\n|  8|j  |2021-11-11 |g  |\n| 10|d  |2021-11-18 |d  |\n\n\n:::\n\n::: {.cell-output-display}\n\n\nTable: S\n\n|  E|F  |G          |D  |\n|--:|:--|:----------|:--|\n|  3|y  |2021-10-21 |o  |\n|  4|e  |2021-10-22 |c  |\n|  6|n  |2021-10-23 |i  |\n|  9|t  |2021-10-24 |d  |\n| 10|r  |2021-10-25 |e  |\n\n\n:::\n:::\n\n\n\n:::\n:::\n\n\n\n## Projecting toy tables \n\n::: {.columns}\n::: {.column}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nR |> \n  dplyr::select(A2,D) |> \n  knitr::kable(caption=\"Projecting R\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Projecting R\n\n|A2 |D  |\n|:--|:--|\n|q  |r  |\n|e  |q  |\n|a  |o  |\n|j  |g  |\n|d  |d  |\n\n\n:::\n:::\n\n\n\n:::\n::: {.column}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nR |> \n  dplyr::select(- where(is.character)) |> \n  knitr::kable(caption=\"Projecting R, all but character columns\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Projecting R, all but character columns\n\n| A1|A3         |\n|--:|:----------|\n|  2|2021-10-21 |\n|  4|2021-10-28 |\n|  6|2021-11-04 |\n|  8|2021-11-11 |\n| 10|2021-11-18 |\n\n\n:::\n:::\n\n\n\n\n:::\n::: \n\n\n\n\n\n\n\n## Projecting `flights` on `origin`  and `dest`\n\n\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nflights |>\n  select(origin, dest) |>  #<<\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  origin dest \n  <chr>  <chr>\n1 EWR    IAH  \n2 LGA    IAH  \n3 JFK    MIA  \n4 JFK    BQN  \n5 LGA    ATL  \n6 EWR    ORD  \n```\n\n\n:::\n:::\n\n\n\nA more readable equivalent of\n\n```{.r}\nhead(select(flights, origin, dest), 10)\n```\n\nor \n\n```{.sql}\nSELECT \n  origin, dest\nFROM \n  flights\nLIMIT 6;\n```\n\n\n\n\n\n\n\n\n\n## $\\sigma(R, \\text{condition})$\n\n- A selection/filtering operation is defined by a condition that can be checked on the rows of tables with convenient schema\n\n- $\\sigma(R, \\text{condition})$ returns a table with the same schema as $R$\n\n- The resulting table contains the rows/tuples of $R$ that satisfy $\\text{condition}$\n\n- $\\sigma(R, \\text{FALSE})$ returns an empty table with the same schema as $R$\n\n\n\n\n\n\n## Chaining filtering and projecting\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nstart <- date(\"2021-10-27\")\nend <- start + 21\n\nR |>\n#  filter(A2 > \"n\") |>  #<<\n  filter(between(A3, start, end)) |>\n  select(A1, A3) #<<\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n     A1 A3        \n  <dbl> <date>    \n1     4 2021-10-28\n2     6 2021-11-04\n3     8 2021-11-11\n```\n\n\n:::\n:::\n\n\n\n\n::: {.aside}\nFiltering dropped one row\n\nProjecting dropped two columns\n\n:::\n\n\n\n## Selecting `flights` based on `origin`  and `dest`\n\nand then projecting on `dest, time_hour, carrier`\n\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nflights |>\n  filter(dest %in% c('ATL', 'LAX'), #<<\n         origin == 'JFK') |>\n  select(dest, time_hour, carrier) |> #<<\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  dest  time_hour           carrier\n  <chr> <dttm>              <chr>  \n1 LAX   2013-01-01 06:00:00 UA     \n2 ATL   2013-01-01 06:00:00 DL     \n3 LAX   2013-01-01 07:00:00 VX     \n4 LAX   2013-01-01 07:00:00 B6     \n5 LAX   2013-01-01 07:00:00 AA     \n6 ATL   2013-01-01 08:00:00 DL     \n```\n\n\n:::\n:::\n\n\n\nIn SQL ({{< fa database >}} parlance:\n\n```{.sql}\nSELECT \n  dest, time_hour, carrier\nFROM \n  flights\nWHERE \n  dest IN ('ATL', 'LAX') AND\n  origin = 'JFK'\nLIMIT 6\n```\n\n\n\n\n\n\n## Logical operations\n\n\n- `filter(R, condition_1, condition_2)` is meant to return the rows of `R` that satisfy `condition_1` **and** `condition_2`\n\n- `filter(R, condition_1 & condition_2)` is an equivalent formulation\n\n- `filter(R, condition_1 | condition_2)` is meant to return the rows of `R` that satisfy `condition_1` **or** `condition_2` (possibly both)\n\n- `filter(R, xor(condition_1,condition_2))` is meant to return the rows of `R` that satisfy **either** `condition_1` **or** `condition_2` (just one of them)\n\n- `filter(R, ! condition_1)` is meant to return the rows of `R` that **do not** satisfy  `condition_1`\n\n\n\n<!-- ## Overview of set and boolean operations\n\n\n![](/images/transform-logical.png)\n -->\n\n\n## {{< fa skull-crossbones >}} Missing values!\n\nNumerical column `dep_time` contains many `NA's` (missing values)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# flights |> pull(dep_time) |> summary()\nsummary(flights$dep_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      1     907    1401    1349    1744    2400    8255 \n```\n\n\n:::\n:::\n\n\n\n{{< fa hand-point-right >}} Missing values (`NA` and variants) should\nbe handled with care\n\n\n\n\n```{.r .cell-code}\nNA & TRUE\n```\n\n[1] NA\n\n```{.r .cell-code}\nNA | TRUE\n```\n\n[1] TRUE\n\n\n\n\n\n## Truth tables for three-valued logic  {.smaller}\n\n::: {.columns}\n::: {.column}\n\n{{< fa exclamation-triangle >}} {{< fa brands r-project >}} uses _three-valued logic_\n\n{{< fa hand-point-right >}} Generate complete truth tables for `and, or, xor`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv <- c(TRUE, FALSE, NA) # truth values\n\nlist_tt <- map(c(`&`, `|`, xor),  #<<\n               ~ outer(v, v, .x)) #<<\n\nfor (i in seq_along(list_tt)){\n  colnames(list_tt[[i]]) <- v\n  rownames(list_tt[[i]]) <- v\n}\n\nnames(list_tt) <- c('& AND',\n                    'OR',\n                    'XOR')\n```\n:::\n\n\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"40%\"}\n\n\n<table class=\" lightable-minimal\" style='font-family: \"Trebuchet MS\", verdana, sans-serif; width: auto !important; '>\n<caption>&amp; AND</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\">   </th>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> TRUE </th>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> FALSE </th>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> NA </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> NA </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n</tbody>\n</table><br>\n\n<!-- -->\n\n<table class=\" lightable-minimal\" style='font-family: \"Trebuchet MS\", verdana, sans-serif; width: auto !important; '>\n<caption>OR</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\">   </th>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> TRUE </th>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> FALSE </th>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> NA </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> NA </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n</tbody>\n</table><br>\n\n<!-- -->\n\n<table class=\" lightable-minimal\" style='font-family: \"Trebuchet MS\", verdana, sans-serif; width: auto !important; '>\n<caption>XOR</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\">   </th>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> TRUE </th>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> FALSE </th>\n   <th style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> NA </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> FALSE </td>\n   <td style=\"text-align:left;\"> TRUE </td>\n   <td style=\"text-align:left;\"> FALSE </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;background-color: lightgray !important;\"> NA </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> NA </td>\n  </tr>\n</tbody>\n</table><br>\n\n<!-- -->\n\n\n\n:::\n::: \n\n\n\n\n\n\n## `slice()`: choosing rows based on location\n\n::: {.columns}\n::: {.column}\n\nIn base {{< fa brands r-project >}} dataframe cells can be addressed by\nindices\n\n`flights[5000:5010,seq(1, 19, by=5)]` returns rows `5000:5010` and columns\n`1, 6, 11` from dataframe `flights`\n\nThis can be done in a (verbose) `dplyr` way using `slice()` and `select()`\n\n:::\n::: {.column}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |>\n  slice(5001:5005) |>  #<<\n  select(seq(1, 19, by=5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n   year dep_delay flight distance\n  <int>     <dbl>  <int>    <dbl>\n1  2013         3   4437      602\n2  2013        43   1016      187\n3  2013        -2   2190     1089\n4  2013        -1     91     2576\n5  2013         5   2131      502\n```\n\n\n:::\n:::\n\n\n\n:::\n::: \n\n\n{{< fa hand-point-right >}} combined with aggregation (`group_by()`) variants of `slice_` may be used \nto perform *windowing* operations\n\n{{< fa hand-point-right >}} Useful variant `slice_sample()`\n\n\n\n\n# Joins : multi-table queries   {background-color=\"#1c191c\"}\n\n\n##\n\n::: {.callout-note}\n\n$\\bowtie(R,S, {\\text{condition}})$\n\nstands for\n\n> join rows/tuples of $R$ and rows/tuples of $S$  that satisfy $\\text{condition}$\n\n:::\n\n\n\n\n## `nycflights` tables\n\n::: {.columns}\n::: {.column}\nThe `nycflights13` package  offers five related tables:\n\n- _Fact_ tables:\n  - `flights`\n  - `weather`  (hourly weather conditions at different locations)\n\n- _Dimension_ tables:\n  - `airports`  (airports full names, location, ...)\n  - `planes`    (model, manufacturer, year, ...)\n  - `airlines`  (full names)\n\nThis is an instance of a [Star Schema](https://en.wikipedia.org/wiki/Star_schema)\n\n:::\n\n::: {.column}\n![](/images/schema-nycflights.png)\n\n:::\n::: \n\n\n\n\n## About *Star schemas*\n\n- Fact tables record measurements for a specific event\n\n- Fact tables generally consist of numeric values, and foreign keys to dimensional data where descriptive information is kept\n\n- Dimension tables record informations about entities involved in events recorded in Fact tables\n\n::: {.aside}\n\nFrom [Wikipedia](https://en.wikipedia.org/wiki/Star_schema)]\n\n:::\n\n\n\n## {{< fa wind >}} weather conditions\n\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nweather |>\n  glimpse(width = 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 26,115\nColumns: 15\n$ origin     <chr> \"EWR\", \"EWR\", \"EWR\", \"EWR\", \"…\n$ year       <int> 2013, 2013, 2013, 2013, 2013,…\n$ month      <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ day        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ hour       <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10…\n$ temp       <dbl> 39.02, 39.02, 39.02, 39.92, 3…\n$ dewp       <dbl> 26.06, 26.96, 28.04, 28.04, 2…\n$ humid      <dbl> 59.37, 61.63, 64.43, 62.21, 6…\n$ wind_dir   <dbl> 270, 250, 240, 250, 260, 240,…\n$ wind_speed <dbl> 10.35702, 8.05546, 11.50780, …\n$ wind_gust  <dbl> NA, NA, NA, NA, NA, NA, NA, N…\n$ precip     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ pressure   <dbl> 1012.0, 1012.3, 1012.5, 1012.…\n$ visib      <dbl> 10, 10, 10, 10, 10, 10, 10, 1…\n$ time_hour  <dttm> 2013-01-01 01:00:00, 2013-01…\n```\n\n\n:::\n:::\n\n\n\n\n\n## Connecting `flights`  and `weather`\n\n\nWe want to complement information in `flights` using data `weather`\n\nMotivation: we would like to relate delays (`arr_delay`) and weather conditions\n\n- can we explain (justify) delays using weather data?\n\n- can we predict delays using weather data?\n\n\n\n## {{< fa plane-departure >}} ⋈  {{< fa wind >}}\n\n\n\nFor each flight (row in `flights`)\n\n- `year`, `month`, `day`, `hour` (computed from `time_hour`) indicate\nthe approaximate time of departure\n\n- `origin` indicates the airport where the plane takes off\n\nEach row of `weather` contains corresponding information\n\n{{< fa hand-point-right >}} for each row of `flights` we look for rows of `weather`\nwith matching values in `year`, `month`, `day`, `hour`  and `origin`\n\n{{< fa hand-point-right >}} NATURAL INNER JOIN between the tables\n\n\n\n## `inner_join`: natural join\n\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nf_w <- flights |>\n  inner_join(weather) #<<\n\nf_w |> \n  select(seq(1, \n             ncol(f_w),\n             by=2)) |> \n  glimpse(width=50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 335,220\nColumns: 14\n$ year           <int> 2013, 2013, 2013, 2013, 2…\n$ day            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ sched_dep_time <int> 515, 529, 540, 545, 600, …\n$ arr_time       <int> 830, 850, 923, 1004, 812,…\n$ arr_delay      <dbl> 11, 20, 33, -18, -25, 12,…\n$ flight         <int> 1545, 1714, 1141, 725, 46…\n$ origin         <chr> \"EWR\", \"LGA\", \"JFK\", \"JFK…\n$ air_time       <dbl> 227, 227, 160, 183, 116, …\n$ hour           <dbl> 5, 5, 5, 5, 6, 5, 6, 6, 6…\n$ time_hour      <dttm> 2013-01-01 05:00:00, 201…\n$ dewp           <dbl> 28.04, 24.98, 26.96, 26.9…\n$ wind_dir       <dbl> 260, 250, 260, 260, 260, …\n$ wind_gust      <dbl> NA, 21.86482, NA, NA, 23.…\n$ pressure       <dbl> 1011.9, 1011.4, 1012.1, 1…\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n## Join schema\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 335,220\nColumns: 28\n$ year           <int> 2013, 2013, 2013, 2013, 2…\n$ month          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       <int> 517, 533, 542, 544, 554, …\n$ sched_dep_time <int> 515, 529, 540, 545, 600, …\n$ dep_delay      <dbl> 2, 4, 2, -1, -6, -4, -5, …\n$ arr_time       <int> 830, 850, 923, 1004, 812,…\n$ sched_arr_time <int> 819, 830, 850, 1022, 837,…\n$ arr_delay      <dbl> 11, 20, 33, -18, -25, 12,…\n$ carrier        <chr> \"UA\", \"UA\", \"AA\", \"B6\", \"…\n$ flight         <int> 1545, 1714, 1141, 725, 46…\n$ tailnum        <chr> \"N14228\", \"N24211\", \"N619…\n$ origin         <chr> \"EWR\", \"LGA\", \"JFK\", \"JFK…\n$ dest           <chr> \"IAH\", \"IAH\", \"MIA\", \"BQN…\n$ air_time       <dbl> 227, 227, 160, 183, 116, …\n$ distance       <dbl> 1400, 1416, 1089, 1576, 7…\n$ hour           <dbl> 5, 5, 5, 5, 6, 5, 6, 6, 6…\n$ minute         <dbl> 15, 29, 40, 45, 0, 58, 0,…\n$ time_hour      <dttm> 2013-01-01 05:00:00, 201…\n$ temp           <dbl> 39.02, 39.92, 39.02, 39.0…\n$ dewp           <dbl> 28.04, 24.98, 26.96, 26.9…\n$ humid          <dbl> 64.43, 54.81, 61.63, 61.6…\n$ wind_dir       <dbl> 260, 250, 260, 260, 260, …\n$ wind_speed     <dbl> 12.65858, 14.96014, 14.96…\n$ wind_gust      <dbl> NA, 21.86482, NA, NA, 23.…\n$ precip         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pressure       <dbl> 1011.9, 1011.4, 1012.1, 1…\n$ visib          <dbl> 10, 10, 10, 10, 10, 10, 1…\n```\n\n\n:::\n:::\n\n\n\n\n##\n\nThe schema of the result is the union of the schemas of the operands\n\nA tuple from `flights` matches a tuple from `weather` if the tuple have the same values in the common columns:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"      \"temp\"          \n[21] \"dewp\"           \"humid\"          \"wind_dir\"       \"wind_speed\"    \n[25] \"wind_gust\"      \"precip\"         \"pressure\"       \"visib\"         \n```\n\n\n:::\n:::\n\n\n\n\n\n## Which columns are used when joining tables $R$ and $S$?\n\n- _default behavior_ of `inner_join`: all columns shared by  $R$ and $S$. Common columns  have the same name\nin both schema. They are expected to have the same class\n\n- _manual definition_: in many settings, we  want to overrule the default behavior. We specify\nmanually which column from $R$ should match which column from $S$\n\n\n\n## Natural join of  `flights`  and `weather`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncommon_names <- base::intersect(names(weather),\n                                names(flights))\n\nsetequal(\n  inner_join(flights, weather),\n  inner_join(flights,\n             weather,\n             by=common_names)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\n\n## {{< fa brain >}} Are you surprised by the next chunk?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndtu  <- inner_join(flights,\n           weather,\n           by=c(\"year\", \"month\", \"day\", \"origin\", \"hour\"))\n\ndtv <- inner_join(flights,\n           weather,\n           by=c(\"origin\", \"time_hour\"))\n\n# setequal(dtu, dtv)\n```\n:::\n\n\n\nRecall that columns `year`, `month` `day` `hour` can be computed from  `time_hour`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |>\n  filter(year!=year(time_hour) |\n         month!=month(time_hour) |\n         day!=day(time_hour) |\n         hour!=hour(time_hour)) |>\n  nrow()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n## The two results do not have the same schema!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetdiff(colnames(dtv), colnames(dtu))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"year.x\"    \"month.x\"   \"day.x\"     \"hour.x\"    \"time_hour\" \"year.y\"   \n[7] \"month.y\"   \"day.y\"     \"hour.y\"   \n```\n\n\n:::\n\n```{.r .cell-code}\nsetdiff(colnames(dtu), colnames(dtv))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"year\"        \"month\"       \"day\"         \"hour\"        \"time_hour.x\"\n[6] \"time_hour.y\"\n```\n\n\n:::\n:::\n\n\n\n\n## Fixing\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndtu  <- inner_join(flights,\n           weather,\n           by=c(\"year\", \"month\", \"day\", \"origin\", \"hour\"),\n           suffix= c(\"\", \".y\")) |>  #<<\n           select(-ends_with(\".y\"))  #<<\n\ndtv <- inner_join(flights,\n           weather,\n           by=c(\"origin\", \"time_hour\"),\n           suffix= c(\"\", \".y\")) |>  #<<\n           select(-ends_with(\".y\"))  #<<\n\nsetequal(dtu, dtv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\n\n## About `inner_join`\n\n::: {.columns}\n::: {.column}\n\n```{.r}\ninner_join(\n  x, y,\n  by = NULL,      #<<\n  copy = FALSE,\n  suffix = c(\".x\", \".y\"), #<<\n  ...,\n  keep = FALSE,  #<<\n  na_matches = \"na\")  #<<\n```\n\n:::\n::: {.column}\n- `by`:\n  - `by=c(\"A1\", \"A3\", \"A7\")` row `r` from `R` and `s` from `S` match if `r.A1 == s.A1`,\n  `r.A3 == s.A3`,   `r.A7 == s.A7`\n  - `by=c(\"A1\"=\"B\", \"A3\"=\"C\", \"A7\"=\"D\")` row `r` from `R` and `s` from `S` match if `r.A1 == s.B`,\n  `r.A3 == s.C`,   `r.A7 == s.D`\n\n- `suffix`: If there are non-joined duplicate variables in `x` and `y`, these suffixes will be added to the output to disambiguate them.\n\n- `keep`: Should the join keys from _both_ `x` and `y` be preserved in the output?\n\n- `na_matches`: Should NA and NaN values match one another?\n\n::: {.aside}\nFrom online documentation\n\n:::\n\n:::\n::: \n\n\n\n\n\n\n## Join flavors\n\nDifferent flavors of `join` can be used to join one table to columns from another, matching values with the rows that they correspond to\n\nEach join retains a different combination of values from the tables\n\n. . .\n\n- `left_join(x, y, by = NULL, suffix = c(\".x\", \".y\"), ...)` Join matching values from `y` to `x`.\nRetain all rows of `x` padding missing values from `y` by `NA`\n\n- `semi_join` ...\n\n- `anti_join` ...\n\n\n\n\n\n## Toy examples : `inner_join`  {.smaller}\n\n::: {.columns}\n::: {.column width=\"40%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: R\n\n| A1|A2 |A3         |D  |\n|--:|:--|:----------|:--|\n|  2|q  |2021-10-21 |r  |\n|  4|e  |2021-10-28 |q  |\n|  6|a  |2021-11-04 |o  |\n|  8|j  |2021-11-11 |g  |\n| 10|d  |2021-11-18 |d  |\n\n\n:::\n\n::: {.cell-output-display}\n\n\nTable: S\n\n|  E|F  |G          |D  |\n|--:|:--|:----------|:--|\n|  3|y  |2021-10-21 |o  |\n|  4|e  |2021-10-22 |c  |\n|  6|n  |2021-10-23 |i  |\n|  9|t  |2021-10-24 |d  |\n| 10|r  |2021-10-25 |e  |\n\n\n:::\n:::\n\n\n:::\n\n::: {.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: inner_join(S, R, by=c(\"E\"=\"A1\"))\n\n|  E|F  |G          |D.x |A2 |A3         |D.y |\n|--:|:--|:----------|:---|:--|:----------|:---|\n|  4|e  |2021-10-22 |c   |e  |2021-10-28 |q   |\n|  6|n  |2021-10-23 |i   |a  |2021-11-04 |o   |\n| 10|r  |2021-10-25 |e   |d  |2021-11-18 |d   |\n\n\n:::\n:::\n\n\n\n:::\n:::\n\n\n\n\n\n## Toy examples : `left_join`  {.smaller}\n\n::: {.columns}\n::: {.column width=\"30%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: R\n\n| A1|A2 |A3         |D  |\n|--:|:--|:----------|:--|\n|  2|q  |2021-10-21 |r  |\n|  4|e  |2021-10-28 |q  |\n|  6|a  |2021-11-04 |o  |\n|  8|j  |2021-11-11 |g  |\n| 10|d  |2021-11-18 |d  |\n\n\n:::\n\n::: {.cell-output-display}\n\n\nTable: S\n\n|  E|F  |G          |D  |\n|--:|:--|:----------|:--|\n|  3|y  |2021-10-21 |o  |\n|  4|e  |2021-10-22 |c  |\n|  6|n  |2021-10-23 |i  |\n|  9|t  |2021-10-24 |d  |\n| 10|r  |2021-10-25 |e  |\n\n\n:::\n:::\n\n\n\n:::\n\n::: {.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: left_join(S, R, by=c(\"E\"=\"A1\"))\n\n|  E|F  |G          |D.x |A2 |A3         |D.y |\n|--:|:--|:----------|:---|:--|:----------|:---|\n|  3|y  |2021-10-21 |o   |NA |NA         |NA  |\n|  4|e  |2021-10-22 |c   |e  |2021-10-28 |q   |\n|  6|n  |2021-10-23 |i   |a  |2021-11-04 |o   |\n|  9|t  |2021-10-24 |d   |NA |NA         |NA  |\n| 10|r  |2021-10-25 |e   |d  |2021-11-18 |d   |\n\n\n:::\n:::\n\n\n\n:::\n:::\n\n\n\n## Toy examples : `semi_join` `anti_join`  {.smaller}\n\n::: {.columns}\n::: {.column width=\"40%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: R\n\n| A1|A2 |A3         |D  |\n|--:|:--|:----------|:--|\n|  2|q  |2021-10-21 |r  |\n|  4|e  |2021-10-28 |q  |\n|  6|a  |2021-11-04 |o  |\n|  8|j  |2021-11-11 |g  |\n| 10|d  |2021-11-18 |d  |\n\n\n:::\n\n::: {.cell-output-display}\n\n\nTable: S\n\n|  E|F  |G          |D  |\n|--:|:--|:----------|:--|\n|  3|y  |2021-10-21 |o  |\n|  4|e  |2021-10-22 |c  |\n|  6|n  |2021-10-23 |i  |\n|  9|t  |2021-10-24 |d  |\n| 10|r  |2021-10-25 |e  |\n\n\n:::\n:::\n\n\n\n:::\n\n\n::: {.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: semi_join(S, R, by=c(\"E\"=\"A1\"))\n\n|  E|F  |G          |D  |\n|--:|:--|:----------|:--|\n|  4|e  |2021-10-22 |c  |\n|  6|n  |2021-10-23 |i  |\n| 10|r  |2021-10-25 |e  |\n\n\n:::\n:::\n\n\n\n<br><br>\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: anti_join(S, R, by=c(\"E\"=\"A1\"))\n\n|  E|F  |G          |D  |\n|--:|:--|:----------|:--|\n|  3|y  |2021-10-21 |o  |\n|  9|t  |2021-10-24 |d  |\n\n\n:::\n:::\n\n\n\n:::\n::: \n\n\n\n\n## Conditional/ $\\theta$ -join\n\nIn relational databases, joins are not restricted to _natural joins_\n\n. . .\n\n$$U \\leftarrow R \\bowtie_{\\theta} S$$\n\nreads as\n\n$$\\begin{array}{rl} T & \\leftarrow R \\times S\\\\ U & \\leftarrow \\sigma(T, \\theta)\\end{array}$$\n\nwhere\n\n- $R \\times S$ is the _cartesian product_ of $R$ and $S$\n\n- $\\theta$ is a boolean expression that can be evaluated on any tuple of $R \\times S$\n\n## Do we need conditional/ $\\theta$ -joins?\n\n::: {.callout-note}\n\n{{< fa hand-point-right >}}: We can implement $\\theta$/conditional-joins by pipelining a cross product and a filtering\n\n:::\n\n. . .\n\n::: {.callout-caution}\n\n{{< fa skull-crossbones >}}: Cross products are costly:\n\n+ $\\#\\text{rows}(R \\times S) = \\#\\text{rows}(R) \\times \\#\\text{rows}(S)$\n+ $\\#\\text{cols}(R \\times S) = \\#\\text{cols}(R) + \\#\\text{cols}(S)$\n\n:::\n\n## Do we need conditional/ $\\theta$ -joins? \n\n::: {.callout-note}\n\n{{< fa database >}}: RDBMS use query planning and optimization, indexing to circumvent the cross product bottleneck (when possible)\n\n:::\n\n. . .\n\n::: {.callout-tip}\n\n{{< fa brands r-project >}}: if we need to perform a $\\theta$-join\n\n  + outsource it to a RDBMS, or\n  + design an ad hoc pipeline\n\n:::\n\n\n::: {.aside}\n\n[About conditional join](https://www.r-bloggers.com/2018/02/in-between-a-rock-and-a-conditional-join/)\n\n:::\n\n\n\n\n## A conditional join between `flights` and `weather`\n\n- The natural join between `flights` and `weather` we implemented can be regarded as an ad hoc conditional join between normalized versions of `weather` and `flights` {{< fa lightbulb >}}\n\n\n- Table `flights` and `weather` are redundant: `year`, `month`, `day`, `hour` can be computed from `time_hour`\n\n\n- Assume `flights` and `weather` are trimmed so as to become irredundant\n\n\n\n- The conditional join is then based on _truncations_ of variables `time_hour`\n\n```{.sql}\nSELECT \n  *\nFROM \n  flights AS f, weather AS w\nWHERE \n  date_trunc('hour', f.time_hour) = date_trunc('hour', w.time_hour)\n```\n\n- Adding redundant columns to `flights` and `weather` allows us to transform\na tricky conditional join into a simple natural join {{< fa champagne-glass >}}\n\n\n::: {.aside}\n\n[PostgreSQL documentation](https://www.postgresql.org/docs/14/index.html)\n\n:::\n\n\n# Creating new columns  {background-color=\"#1c191c\"}\n\n\n## \n\nCreation of new columns may happen\n\n- on the fly\n\n- when altering (enriching) the schema of a table\n\nIn databases, creation of new columns may be the result of a query or be the result of altering a table schema with `ALTER TABLE ADD COLUMN ...`\n\nIn `tidyverse()` we use verbs `mutate`  or `add_column` to add columns to the input table\n\n\n\n## `mutate`\n\n::: {.columns}\n::: {.column}\n\n```{.r}\nmutate(   #<<\n  .data,\n  new_col= expression, #<<\n  ...,   #<<\n  .keep = c(\"all\", \"used\", \"unused\", \"none\"),\n  .before = NULL,\n  .after = NULL\n)\n```\n\n:::\n::: {.column}\n\n`.data`: the input data frame\n\n`new_col= expression`:\n\n-  `new_col` is the name of a new column\n\n-  `expression` is evaluated on each row of `.data` or it is a vector of length `1`\n\n- `all` is the default behavior, retains all columns from `.data`\n\n\n:::\n::: \n\n\n\n\n\n## Creating a categorical column to spot large delays\n\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nbreaks_delay <- with(flights,\n  c(min(arr_delay, na.rm=TRUE),\n    0, 30,\n    max(arr_delay, na.rm=TRUE))\n)\n\nlevel_delay <- c(\"None\",\n                 \"Moderate\",\n                 \"Large\")\n\nflights |>\n  mutate(large_delay = cut(\n    arr_delay,  #<<\n    breaks=breaks_delay, #<<\n    labels=level_delay,  #<<\n    ordered_result=TRUE)) |>   #<<\n  select(large_delay, arr_delay) |>\n  sample_n(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  large_delay arr_delay\n  <ord>           <dbl>\n1 Large             219\n2 Moderate           18\n3 None              -19\n4 None              -16\n5 None               -1\n```\n\n\n:::\n:::\n\n\n\n\n\n\n##\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nflights |>\n  mutate(foo = if_else(arr_time > sched_arr_time,        #<<\n                              arr_time - sched_arr_time,\n                              0L,\n                              missing = NA_integer_)) |>\n  group_by( (foo >0) & abs(foo - arr_delay)  > 100) |>\n  summarise(N=n())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  `(foo > 0) & abs(foo - arr_delay) > 100`      N\n  <lgl>                                     <int>\n1 FALSE                                    322281\n2 TRUE                                       5157\n3 NA                                         9338\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Changing the class of a column\n\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nflights |>\n  mutate(large_delay = cut(arr_delay,  #<<\n    breaks=breaks_delay,\n    labels=level_delay,\n    ordered_result=TRUE),\n    origin = as.factor(origin), #<<\n    dest = as.factor(dest)    #<<\n  ) |>\n  select(\n    large_delay,\n    arr_delay,\n    origin,\n    dest) |>\n  sample_n(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  large_delay arr_delay origin dest \n  <ord>           <dbl> <fct>  <fct>\n1 None              -44 LGA    CVG  \n2 None              -15 EWR    DAY  \n3 Large             136 EWR    DEN  \n4 None               -9 EWR    TPA  \n5 Moderate           14 LGA    TPA  \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n# Tidy tables  {background-color=\"#1c191c\"}\n\n\n\n\n## Tidying tables is part of data cleaning   {.smaller }\n\n> A (tidy) dataset is a collection of values, usually either numbers (if quantitative) or strings (if qualitative)\n\n> Values are organised in two ways\n\n> Every value belongs to a _variable_ and an _observation_\n\n> A _variable_ contains all values that measure the same underlying attribute (like height, temperature, duration) across _units_\n\n> An _observation_ contains all values measured on the same _unit_ (like a person, or a day, or a race) across attributes\n\n> The principles of tidy data are tied to those of relational databases and Codd's relational algebra\n\n\n::: {.aside}\n\n[ {{< fa book >}} The tidy data paper](https://vita.had.co.nz/papers/tidy-data.html)\n\n:::\n\n##  Codd's principles  {.smaller}\n\n\n\n1. Information is represented logically in *tables*\n2. Data must be *logically accessible* by table, primary key, and column.\n3. *Null* values must be uniformly treated as “missing information,” not as empty strings, blanks, or zeros.\n4. Metadata (data about the database) must be stored in the database just as regular data is\n5. A single language must be able to define data, views, integrity\nconstraints, *authorization*, *transactions*, and data manipulation\n1. *Views* must show the updates of their *base tables* and vice versa\n2. A single operation must be available to do each of the following\noperations: retrieve data, insert data, update data, or delete data\n1. Batch and end-user operations are *logically separate* from physical\nstorage and access methods\n1. Batch and end-user operations can change the database schema without having to recreate it or the applications built upon it\n2.  *Integrity* constraints must be available and stored in the metadata, not in\nan application program\n1.  The data manipulation language of the relational system should not care\nwhere or how the physical data is distributed and should not require\nalteration if the physical data is centralized or distributed\n1.  Any *row processing* done in the system must obey the same *integrity rules* and *constraints* that set-processing operations do\n\n\n\n\n\n## {{< fa bullhorn >}}\n\n{{< fa hand-point-right >}} `dplyr` functions expect and return _tidy_ tables\n\nIn a _tidy_ table\n\n- Each variable is a column\n\n- Each observation is a row\n\n- Every cell is a single value\n\n\n::: {.aside}\n[{{< fa book >}} The tidy data paper](https://vita.had.co.nz/papers/tidy-data.html)]\n:::\n\n##\n\n{{< fa hand-point-right >}} In order to tell whether a table is tidy, we need to know what is the _population_ under investigation,\nwhat are the observations/individuals, which measures are performed on each individual, ...\n\n\n\n## Untidy data\n\n> Column headers are values, not variable names.\n\n> Multiple variables are stored in one column.\n\n> Variables are stored in both rows and columns.\n\n> Multiple types of observational units are stored in the same table.\n\n> A single observational unit is stored in multiple tables.\n\n> ...\n\n\n\n\n{{< fa tools >}} \n\n\n\n\n\n\n## Functions from `tidyr::...`\n\n- `pivot_wider` and `pivot_longer`\n\n- `separate` and  `unite`\n\n- Handling missing values with `complete`, `fill`, ...\n\n- ...\n\n[`tidyr` website](https://tidyr.tidyverse.org)\n\n\n\n\n## Pivot longer  {.smaller}\n\n::: {.columns}\n::: {.column width=\"30%\"}\n\n`pivot_longer()` is commonly needed to tidy wild-caught datasets as they often optimise for ease of data entry or ease of comparison rather than ease of analysis.\n\n:::\n\n::: {.column width=\"70%\"}\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nmessy <- tibble::tribble(\n  ~row, ~a, ~b, ~c,\n  \"A\", 1, 4, 7,\n  \"B\", 2, 5, 8,\n  \"C\", 3, 6, 9,\n)\nmessy |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|row |  a|  b|  c|\n|:---|--:|--:|--:|\n|A   |  1|  4|  7|\n|B   |  2|  5|  8|\n|C   |  3|  6|  9|\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nmessy_long <- messy |> \n  pivot_longer(\n    cols=c(-row),  #<<\n    names_to = \"name\",\n    values_to = \"value\")\n  \nmessy_long  |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|row |name | value|\n|:---|:----|-----:|\n|A   |a    |     1|\n|A   |b    |     4|\n|A   |c    |     7|\n|B   |a    |     2|\n|B   |b    |     5|\n|B   |c    |     8|\n|C   |a    |     3|\n|C   |b    |     6|\n|C   |c    |     9|\n\n\n:::\n:::\n\n\n\n:::\n::: \n\n::: {.aside}\n\n> `pivot_longer()` makes datasets longer by increasing the number of rows and decreasing the number of columns. I don’t believe it makes sense to describe a dataset as being in “long form”. Length is a relative term, and you can only say (e.g.) that dataset A is longer than dataset B.\n\n:::\n\n## Pivot wider\n\n::: {.columns}\n::: {.column}\n\n```{.r}\npivot_wider(  #<<\n  data,\n  id_cols = NULL, #<<\n  names_from = name, #<<\n  names_prefix = \"\",\n  values_from = value, #<<\n  ...\n)\n```\n{{< fa hand-point-right >}} some optional arguments are missing\n\n:::\n::: {.column}\n\nWhen reporting, we often use `pivot_wider` (explicitely or implicitely)\nto make results more readable, possibly to conform to a tradition\n\n- Life tables in demography and actuarial science\n- Longitudinal data\n- See slide [How many flights per day of week per departure airport?](#aggregate-pivot-wider)\n\n:::\n::: \n\n\n## `pivot_wider()` in action\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nmessy_long |>\n  pivot_wider( \n  id_cols = c(\"row\"), #<<\n  names_from = name, #<<\n  names_prefix = \"\",\n  values_from = value\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  row       a     b     c\n  <chr> <dbl> <dbl> <dbl>\n1 A         1     4     7\n2 B         2     5     8\n3 C         3     6     9\n```\n\n\n:::\n:::\n\n\n\n# Aggregations  {background-color=\"#1c191c\"}\n\n\n\n## How many flights per carrier?\n\n\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nflights |>\n  group_by(carrier) |>  #<<\n  summarise(count=n()) |>  #<<\n  arrange(desc(count))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 16 × 2\n   carrier count\n   <chr>   <int>\n 1 UA      58665\n 2 B6      54635\n 3 EV      54173\n 4 DL      48110\n 5 AA      32729\n 6 MQ      26397\n 7 US      20536\n 8 9E      18460\n 9 WN      12275\n10 VX       5162\n11 FL       3260\n12 AS        714\n13 F9        685\n14 YV        601\n15 HA        342\n16 OO         32\n```\n\n\n:::\n:::\n\n\n\n```{.sql}\nSELECT \n  carrier, COUNT(*) AS n\nFROM \n  flights\nGROUP BY \n  carrier\nORDER BY \n  n DESCENDING\n```\n\n\n## How many flights per day of week per departure airport?  {.smaller}\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nflights |>\n  group_by(origin,  wday(time_hour, abbr=T, label=T)) |>  #<<\n  summarise(count=n(), .groups=\"drop\") |>       #<<\n  rename(day_of_week=`wday(time_hour, abbr = T, label = T)`) |>\n  pivot_wider(  #<<\n    id_cols=\"origin\",   #<<\n    names_from=\"day_of_week\", #<<\n    values_from=\"count\") |>  #<<\n  kable(caption=\"Departures per day\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Departures per day\n\n|origin | dim\\.| lun\\.| mar\\.| mer\\.| jeu\\.| ven\\.| sam\\.|\n|:------|-----:|-----:|-----:|-----:|-----:|-----:|-----:|\n|EWR    | 16425| 18329| 18243| 18180| 18169| 18142| 13347|\n|JFK    | 15966| 16104| 16017| 15841| 16087| 16176| 15088|\n|LGA    | 13966| 16257| 16162| 16039| 15963| 15990| 10285|\n\n\n:::\n:::\n\n\n\n\n\n\n# Window queries  {background-color=\"#1c191c\"}\n\n\n\n## Window queries \n\nAssume we want to answer the question: for each day of week (Monday, Tuesday, ...), what are the five carriers that experience the largest average delay?\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nflights |>\n  group_by(weekdays(time_hour), carrier) |>\n  summarise(avg_dep_delay=mean(dep_delay, na.rm=T)) |>\n  slice_max(n=2, order_by=avg_dep_delay)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 14 × 3\n# Groups:   weekdays(time_hour) [7]\n   `weekdays(time_hour)` carrier avg_dep_delay\n   <chr>                 <chr>           <dbl>\n 1 dimanche              F9               23.7\n 2 dimanche              VX               17.4\n 3 jeudi                 YV               29.7\n 4 jeudi                 F9               26.5\n 5 lundi                 FL               24.8\n 6 lundi                 EV               23.4\n 7 mardi                 YV               19.1\n 8 mardi                 FL               17.7\n 9 mercredi              OO               52  \n10 mercredi              HA               24.5\n11 samedi                OO               41  \n12 samedi                F9               15.8\n13 vendredi              OO               29  \n14 vendredi              F9               25.6\n```\n\n\n:::\n:::\n\n\n\n## The SQL way {.smaller}\n\n```{.sql}\nWITH R AS (\n  SELECT \n    EXTRACT(dow FROM time_hour) AS day_of_week,\n    carrier,\n    AVG(dep_delay) AS avg_dep_delay\n  FROM \n    flights\n  GROUP BY \n    EXTRACT(dow FROM time_hour), carrier\n), S AS (\n  SELECT \n    day_of_week,\n    carrier,\n    rank() OVER (PARTITION by day_of_week ORDER BY avg_dep_delay DESC) AS rnk\n  FROM \n    R\n)\n\nSELECT \n  day_of_week, \n  carrier, \n  rnk\nFROM \n  S\nWHERE \n  rnk <= 10 ;\n```\n\n\n\n\n## Sliding windows and package `slider`\n\nTODO\n\n\n\n# Pipelines/chaining operations {background-color=\"#1c191c\"}\n\n\n\n## `|>`, `%>%` and other pipes  {.smaller}\n\n- All `dplyr` functions take a table as the first argument\n\n- Rather than forcing the user to either save intermediate objects or nest functions, `dplyr` provides the `|>` operator from `magrittr`\n\n- `x |> f(y)` turns into `f(x, y)`\n\n- The result from one step is  _piped_ into the next step\n\n- Use `|>`  to rewrite multiple operations that you can read left-to-right/top-to-bottom\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng(f(x, y), z)\n\nx |>\n  f(y) |>\n  g(z)\n```\n:::\n\n\n\n::: {.aside}\n\nFrom [dplyr vignette](https://dplyr.tidyverse.org/articles/dplyr.html)\n\n:::\n\n\n\n\n## Magrittr `%>%`\n\n::: {.columns}\n::: {.column}\n\n- `%>%` is not tied to `dplyr`\n- `%>%` can be used with packages from `tidyverse`\n- `%>%` can be used outside `tidyverse` that is with functions which take a table (or something else) as a second, third or keyword argument\n\n{{< fa magic >}} Use pronoun `.` to denote the LHS of the pipe expression\n\n:::\n\n::: {.column}\n\nSecond argument of `g` has the same type as the result of `f`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng(z, f(x, y))\n\nx %>%\n  f(y) %>%\n  g(z, .)   #<<\n```\n:::\n\n\n\n`x %>% f(y)` is a shorthand for `x %>% f(., y)`\n\n:::\n::: \n\n\n\n\n\n## Standard pipe `|>` (version > 4.)\n\nAs of version 4.1 (2021), base {{< fa brands r-project >}} offers a pipe operator denoted by `|>`\n\n::: {.columns}\n::: {.column}\n\n`x |> f(y)` turns into `f(x, y)`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng(f(x, y), z)\n\nx |>\n  f(y) |>\n  g(z)\n```\n:::\n\n\n:::\n::: {.column}\n\n{{< fa hand-point-right >}} the standard pipe `|>` has no pronoun/placeholder to denote the LHS of the pipe expression\n\nThe roundabout consists in using another new construct `\\(x)`\n\n```{.r}\ng(z, w)\n\nx |>\n  (\\(x) g(z, w=x))()\n```\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\"une\" |>\n  (\\(x) str_c(\"ceci n'est pas\", x, sep=\" \"))() |>\n  str_c(\"pipe\", sep=\" \") |>\n  cat()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nceci n'est pas une pipe\n```\n\n\n:::\n:::\n\n\n:::\n::: \n\n\n::: {.aside}\n\nSee [Blog on the new standard pipe](https://www.r-bloggers.com/2021/05/the-new-r-pipe/)]\n\n:::\n\n## Other pipes\n\n`Magrittr` offers several variants of `|>`\n\n- Tee operator `%T>%`\n- Assignement pipe `%<>%`\n- Exposition operator `%$%`\n- ...  \n\nSee [pipes for beginners](https://www.r-bloggers.com/2017/12/pipes-in-r-tutorial-for-beginners/)\n\n\n{{< fa exclamation-triangle >}} Base {{< fa brands r-project >}}  has a `pipe()` function  to manipulate connections (Files, URLs, ...)\n\n\n\n## {{< fa book-reader >}} References\n\n- [R for Data Science](https://r4ds.had.co.nz)\n  + [Data transformation](https://r4ds.had.co.nz/transform.html)\n- Rstudio cheat sheets\n  + [dplyr](https://www.rstudio.com/resources/cheatsheets/)\n  + [tidyr](https://www.rstudio.com/resources/cheatsheets/)\n  + [datatable](https://www.rstudio.com/resources/cheatsheets/)\n  + [readr](https://www.rstudio.com/resources/cheatsheets/)\n\n\n\n\n\n\n\n\n\n\n# The End   {background-color=\"#1c191c\"}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}